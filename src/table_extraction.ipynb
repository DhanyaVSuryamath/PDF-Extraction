{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96f1c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\text_extraction_libraries_better.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7b50e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\Test.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c59770da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 1)) (0.9.9)\n",
      "Requirement already satisfied: langchain in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 2)) (0.3.27)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 3)) (0.3.33)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: jupyter in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 6)) (0.3.29)\n",
      "Requirement already satisfied: pypdf in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 7)) (5.9.0)\n",
      "Collecting langchain_experimental (from -r requirements.txt (line 8))\n",
      "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 9)) (3.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 10)) (2.3.2)\n",
      "Requirement already satisfied: pdfplumber in c:\\users\\chinmayi suryamath\\desktop\\ml project ecommerce\\nn_pdf\\new_env\\lib\\site-packages (from -r requirements.txt (line 11)) (0.11.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for faiss-gpu\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2895b",
   "metadata": {},
   "source": [
    "# using pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db552ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Library', 'Best For', 'Notes']\n",
      "['PyPDF2', 'Basic text extraction', 'Simple but not good at preserving layout; cannot handle tables well.']\n",
      "['PyMuPDF (fitz)', 'Text with layout + metadata', 'Extracts text by blocks, words, and coordinates — useful for table-like structures.']\n",
      "['PDFMiner.six', 'Detailed text extraction', 'Fine-grained control over text positioning; steeper learning curve.']\n",
      "['PDFPlumber', 'Text + structured extraction', 'Built on PDFMiner; provides easy access to words, lines, bounding boxes.']\n",
      "['pdfrw', 'Low-level PDF manipulation', 'Good for editing/merging PDFs, but not ideal for extraction.']\n",
      "['Slate', 'Wrapper over PDFMiner', 'Easier interface but largely outdated.']\n",
      "['textract', 'Multiple file formats', 'Handles PDFs but relies on other tools; heavier dependency.']\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "with pdfplumber.open(data) as pdf:\n",
    "    for p in pdf.pages:\n",
    "        for t in p.extract_tables():\n",
    "            for r in t:\n",
    "                print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b80d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37506045",
   "metadata": {},
   "source": [
    "# using camelot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd20524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0                   1             2          3        4      5        6        7         8\n",
      "0   Pos              Player          Team       Span  Innings   Runs  Highest  Average  Striking\n",
      "1                                                                       Score               Rate\n",
      "2     1     Sachin Tendular         India  1989-2012      452  18426      200    44.83     86.23\n",
      "3     2    Kumar Sangakkara     Sri Lanka  2000-2015      380  14234      169    41.98     78.86\n",
      "4     3       Ricky Ponting     Australia  1995-2012      365  13704      164    42.03     80.39\n",
      "5     4   Sanath Jayasuriya     Sri Lanka  1989-2011      433  13430      189    32.36      91.2\n",
      "6     5  Mahela Jayawardene     Sri Lanka  1998-2015      418  12650      144    33.37     78.96\n",
      "7     6         Virat Kohli         India  2008-2020      236  11867      183    59.85     93.39\n",
      "8     7      Inzamam-ul-Haq      Pakistan   1991-200      350  11739      137    39.52     74.24\n",
      "9     8       Jacques Kalis  South Africa  1996-2014      314  11579      139    44.36     72.89\n",
      "10    9      Saurav Ganguly         India  1992-2007      300  11363      183    41.02      73.7\n",
      "11   10        Rahul Dravid         India  1996-2011      318  10889      153    39.16     71.24\n"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "\n",
    "# Show all columns in one line\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Increase display width so it doesn't wrap\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "# Read tables\n",
    "a = camelot.read_pdf(data2,  pages=\"all\", flavor=\"stream\")\n",
    "\n",
    "# Print first table\n",
    "print(a[0].df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47711dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd944bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0                             1                                                                                    2\n",
      "0                                                                                         Text Extraction Libraries for PDF (Python)\n",
      "1         Library                      Best For                                                                                Notes\n",
      "2          PyPDF2         Basic text extraction                 Simple but not good at preserving layout; cannot handle tables well.\n",
      "3  PyMuPDF (fitz)   Text with layout + metadata  Extracts text by blocks, words, and coordinates — useful for table-like structures.\n",
      "4    PDFMiner.six      Detailed text extraction                  Fine-grained control over text positioning; steeper learning curve.\n",
      "5      PDFPlumber  Text + structured extraction             Built on PDFMiner; provides easy access to words, lines, bounding boxes.\n",
      "6           pdfrw    Low-level PDF manipulation                         Good for editing/merging PDFs, but not ideal for extraction.\n",
      "7           Slate         Wrapper over PDFMiner                                               Easier interface but largely outdated.\n",
      "8        textract         Multiple file formats                          Handles PDFs but relies on other tools; heavier dependency.\n"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "\n",
    "# Show all columns in one line\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Increase display width so it doesn't wrap\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Prevent column data from being shortened with \"...\"\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Read tables\n",
    "a = camelot.read_pdf(data,  pages=\"all\", flavor=\"stream\")\n",
    "\n",
    "# Print first table\n",
    "print(a[0].df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0d3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc958a5",
   "metadata": {},
   "source": [
    "trying camelot on  scanned image6.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8cf569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\NEW_ENV\\Lib\\site-packages\\camelot\\parsers\\base.py:124: UserWarning: page-1 is image-based, camelot only works on text-based pages.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m a = camelot.read_pdf(image6,  pages=\u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m, flavor=\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Print first table\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\NEW_ENV\\Lib\\site-packages\\camelot\\core.py:938\u001b[39m, in \u001b[36mTableList.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):  \u001b[38;5;66;03m# noqa D105\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tables\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "\n",
    "# Show all columns in one line\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "image6 = r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\PDF_of_table2_image6.pdf\"\n",
    "\n",
    "# Read tables\n",
    "a = camelot.read_pdf(image6,  pages=\"all\", flavor=\"stream\")\n",
    "\n",
    "# Print first table\n",
    "print(a[0].df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "715cecb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Using cached pymupdf-1.26.4-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Using cached pymupdf-1.26.4-cp39-abi3-win_amd64.whl (18.7 MB)\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b73d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "image =r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\image2.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62902cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\image3.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45d69f8",
   "metadata": {},
   "source": [
    "# using PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2664a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Player Team Span Innings Runs Highest Average Striking\n",
      "Score Rate\n",
      "7 Sachin Tendular india 98920122 cro 200 33 36.23\n",
      "2 KumarSangalkara Srilanka +2000-2015 380 wana 169 4198 78.86\n",
      "3 Ricky Ponting ‘Australia 19952012365 13704 164 4203 3039\n",
      "4 Sanath Jayasuriya Srilanka «1989-2011 433 13430 189 32.36 912\n",
      "5S Mahelaayawardene Srilanka 1998-2015. 418 12650 144 3337 78.96\n",
      "6 Virat Kohli India 2008-2020 236 11867 183 59.85 93.39\n",
      "7 Inzamam-ultag Pakistan 1991-200 350 11739 137 3952 7428\n",
      "8 Jacques Kals South Africa 1996-2014 314 11579 139 44.36 739\n",
      "9 Saurav Ganguly India 1992-2007 300, 11363, 183 4102 737\n",
      "10 Rahul Dravid India 1996-2011_318 0889 153 39.16 24\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "doc = fitz.open(image3)\n",
    "for page_num in range(len(doc)):\n",
    "    pix = doc[page_num].get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    print(text)  # extract raw OCR text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8368ade",
   "metadata": {},
   "source": [
    "not able to fetch accurate numerical data when converted from image to string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda5b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90625a45",
   "metadata": {},
   "source": [
    "# extract tabular data using pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17ce6de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image4 = r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\image4_premium_bill.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7e89853",
   "metadata": {},
   "outputs": [],
   "source": [
    "image6 = r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\image6_(of_table2_premium_details).jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "291206c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN RETURN FOR THE PAYMENT OF THE PREMIUM, AND SUBJECT TO ALL THE TERMS OF THIS POLICY,\n",
      "WE WILL PROVIDE YOU THE INSURANCE STATED IN THIS POLICY.\n",
      "\n",
      "THIS POLICY CONSISTS OF THE FOLLOWING COVERAGE PARTS FOR WHICH A PREMIUM IS INDICATED.\n",
      "THIS PREMIUM MAY BE SUBJECT TO ADJUSTMENT. PREMIUM\n",
      "\n",
      "Commercial General Liability Coverage Part $ 1,100.00\n",
      "$\n",
      "$\n",
      "$\n",
      "$\n",
      "$\n",
      "G. ,\n",
      "Tax & Fee Schedule TOTAL ADVANCE PREMIUM $ 1,100.00\n",
      "Tnapercicn. Fes $ 63.99 Minimum & Deposit\n",
      "arin 39.45 TOTAL TAXES & FEES $ 254.45\n",
      "\n",
      "TOTAL $ 1,354.45\n",
      "\n",
      "Form(s) and Endorsement(s) made a part of this policy at time of issue:\n",
      "Refer to Schedule of Forms and Endorsements.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "\n",
    "image = Image.open(image4)\n",
    "text = pytesseract.image_to_string(image)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18d2d977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RATE\n",
      "\n",
      "PREMIUM ADVANCE\n",
      "CODE #- CLASSIFICATION * BASIS Prem/Ops | ProgiComp| PREMIUM\n",
      "Ips\n",
      "\n",
      "secog + Yacane Bulidings ~ not factories ~ 24] 11 500 adsl $62\n",
      "\n",
      "Included | Included\n",
      "Vacant land-Rural - Per Acre -\n",
      "\n",
      "49451 - pirst 500 Acres - OTNFP ti é a0 0809 63\n",
      "Included |Included\n",
      "\n",
      "10105 - Boat storage or moorage st If Any Included Included\n",
      "Included |Included\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "\n",
    "image = Image.open(image6)\n",
    "text = pytesseract.image_to_string(image)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773808e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d90c81f",
   "metadata": {},
   "source": [
    "image to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "203c1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\image6_(of_table2_premium_details).jpg\")\n",
    "\n",
    "# Convert to RGB (needed for PDF)\n",
    "if image.mode == \"RGBA\":\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "# Save as PDF\n",
    "image.save(r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\PDF_of_table2_image6.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568b9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e69e40f1",
   "metadata": {},
   "source": [
    "# pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "602a97fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Library                      Best For                                              Notes\n",
      "0          PyPDF2         Basic text extraction  Simple but not good at preserving layout; cann...\n",
      "1  PyMuPDF (fitz)   Text with layout + metadata  Extracts text by blocks, words, and coordinate...\n",
      "2    PDFMiner.six      Detailed text extraction  Fine-grained control over text positioning; st...\n",
      "3      PDFPlumber  Text + structured extraction  Built on PDFMiner; provides easy access to wor...\n",
      "4           pdfrw    Low-level PDF manipulation  Good for editing/merging PDFs, but not ideal f...\n",
      "5           Slate         Wrapper over PDFMiner             Easier interface but largely outdated.\n",
      "6        textract         Multiple file formats  Handles PDFs but relies on other tools; heavie...\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your single-page PDF\n",
    "pdf_path = r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\text_extraction_libraries_better.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    page = pdf.pages[0]  # take the first (and only) page\n",
    "    tables = page.extract_tables()\n",
    "    \n",
    "    if tables:\n",
    "        table = tables[0]  # get the first table on the page\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(table[1:], columns=table[0])  # first row = header\n",
    "        print(df)\n",
    "\n",
    "        # Save to CSV\n",
    "        df.to_csv(\n",
    "            r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Output\\extracted_tables.csv\",\n",
    "            index=False\n",
    "        )\n",
    "    else:\n",
    "        print(\"❌ No table found in this PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc89a8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0            1                    2                         3                             4                                                 5  Page\n",
      "0                   RETROACTIVE DATE (CG 00 02 ONLY)         None                 None                      None                          None                                              None     1\n",
      "1  This insurance does not apply to \"bodily injur...         None                 None                      None                          None                                              None     1\n",
      "2      BUSINESS DESCRIPTION AND LOCATION OF PREMISES         None                 None                      None                          None                                              None     1\n",
      "3  BUSINESS DESCRIPTION: Propert y Owner\\nLOCATIO...         None                 None                      None                          None                                              None     1\n",
      "4                              CODE#- CLASSIFICATION            *       PREMIUM\\nBASIS                      RATE                          None                                  ADVANCE\\nPREMIUM     1\n",
      "5                                               None         None                 None                  Prem/Ops                Prod/Comp\\nOos                                              None     1\n",
      "6  - Vacant Buildings - not factories -\\n68606\\nO...  a+\\nt +\\ns+  11, 500\\n6\\nI f Any  48.891\\n10.500\\nIncluded  Included\\nIncluded\\nIncluded  562\\nIncluded\\n63\\nIncluded\\nIncluded\\nIncl uded     1\n",
      "7  * PREMIUM BASIS SYMBOLS + = Products/Completed...         None                 None                      None                          None                                              None     1\n",
      "8          PREMIUM FOR THIS COVERAGE PART $ l ,lOOMP         None                 None                      None                          None                                              None     1\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "pdf_path = r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\table2.pdf\"\n",
    "all_tables = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for i, page in enumerate(pdf.pages, start=1):\n",
    "        tables = page.extract_tables()\n",
    "        for table in tables:\n",
    "            try:\n",
    "                # Use first row as header\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])\n",
    "\n",
    "                # Ensure column names are unique\n",
    "                df.columns = pd.io.parsers.ParserBase({'names':df.columns})._maybe_dedup_names(df.columns)\n",
    "\n",
    "            except Exception:\n",
    "                # If header fails, fall back to default numbering\n",
    "                df = pd.DataFrame(table)\n",
    "\n",
    "            df[\"Page\"] = i\n",
    "            all_tables.append(df)\n",
    "\n",
    "# Combine all tables\n",
    "final_df = pd.concat(all_tables, ignore_index=True)\n",
    "print(final_df)\n",
    "final_df.to_csv(r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Output\\extracted_tables_of+table2(pdf).csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dfec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  1 2 3                   4 5 6          7 8 9  ... 18   19 20 21     22 23 24     25 26 Page\n",
      "0    1         Sachin Tendular          India      ...     200        44.83        86.23       1\n",
      "1    3           Ricky Ponting      Australia      ...     164        42.03        80.39       1\n",
      "2    5      Mahela Jayawardene      Sri Lanka      ...     144        33.37        78.96       1\n",
      "3    7          Inzamam-ul-Haq       Pakistan      ...     137        39.52        74.24       1\n",
      "4    9          Saurav Ganguly          India      ...     183        41.02         73.7       1\n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "pdf_path = r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\Test.pdf\"\n",
    "all_tables = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for i, page in enumerate(pdf.pages, start=1):\n",
    "        tables = page.extract_tables()\n",
    "        for table in tables:\n",
    "            try:\n",
    "                # Use first row as header\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])\n",
    "\n",
    "                # Ensure column names are unique\n",
    "                df.columns = pd.io.parsers.ParserBase({'names':df.columns})._maybe_dedup_names(df.columns)\n",
    "\n",
    "            except Exception:\n",
    "                # If header fails, fall back to default numbering\n",
    "                df = pd.DataFrame(table)\n",
    "\n",
    "            df[\"Page\"] = i\n",
    "            all_tables.append(df)\n",
    "\n",
    "# Combine all tables\n",
    "final_df = pd.concat(all_tables, ignore_index=True)\n",
    "print(final_df)\n",
    "final_df.to_csv(r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Output\\extracted_tables_of_Test(pdf).csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8928e81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '1', '', '', 'Sachin Tendular', '', '', 'India', '', '', '1989-2012', '', '', '452', '', '', '18426', '', '', '200', '', '', '44.83', '', '', '86.23', '']\n",
      "['', '3', '', '', 'Ricky Ponting', '', '', 'Australia', '', '', '1995-2012', '', '', '365', '', '', '13704', '', '', '164', '', '', '42.03', '', '', '80.39', '']\n",
      "['', '5', '', '', 'Mahela Jayawardene', '', '', 'Sri Lanka', '', '', '1998-2015', '', '', '418', '', '', '12650', '', '', '144', '', '', '33.37', '', '', '78.96', '']\n",
      "['', '7', '', '', 'Inzamam-ul-Haq', '', '', 'Pakistan', '', '', '1991-200', '', '', '350', '', '', '11739', '', '', '137', '', '', '39.52', '', '', '74.24', '']\n",
      "['', '9', '', '', 'Saurav Ganguly', '', '', 'India', '', '', '1992-2007', '', '', '300', '', '', '11363', '', '', '183', '', '', '41.02', '', '', '73.7', '']\n"
     ]
    }
   ],
   "source": [
    "with pdfplumber.open(r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\Test.pdf\") as pdf:\n",
    "    for page in pdf.pages:\n",
    "        tables = page.extract_tables()\n",
    "        for table in tables:\n",
    "            for row in table:\n",
    "                print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e046206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['', '1', '', '', 'Sachin Tendular', '', '', 'India', '', '', '1989-2012', '', '', '452', '', '', '18426', '', '', '200', '', '', '44.83', '', '', '86.23', '']], [['', '3', '', '', 'Ricky Ponting', '', '', 'Australia', '', '', '1995-2012', '', '', '365', '', '', '13704', '', '', '164', '', '', '42.03', '', '', '80.39', '']], [['', '5', '', '', 'Mahela Jayawardene', '', '', 'Sri Lanka', '', '', '1998-2015', '', '', '418', '', '', '12650', '', '', '144', '', '', '33.37', '', '', '78.96', '']], [['', '7', '', '', 'Inzamam-ul-Haq', '', '', 'Pakistan', '', '', '1991-200', '', '', '350', '', '', '11739', '', '', '137', '', '', '39.52', '', '', '74.24', '']], [['', '9', '', '', 'Saurav Ganguly', '', '', 'India', '', '', '1992-2007', '', '', '300', '', '', '11363', '', '', '183', '', '', '41.02', '', '', '73.7', '']]]\n",
      "Page 1: Found 5 tables\n"
     ]
    }
   ],
   "source": [
    "with pdfplumber.open(r\"C:\\Users\\CHINMAYI SURYAMATH\\Desktop\\ML PROJECT ECOMMERCE\\NN_pdf\\Data\\Test.pdf\") as pdf:\n",
    "    for i, page in enumerate(pdf.pages, start=1):\n",
    "        tables = page.extract_tables()\n",
    "        print(tables)\n",
    "        print(f\"Page {i}: Found {len(tables)} tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd7169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEW_ENV (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
